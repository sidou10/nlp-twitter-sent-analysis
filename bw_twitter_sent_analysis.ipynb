{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis on Tweets\n",
    "The following problem is a supervised multi-class classification problem of sentiment analysis. We will go through all the main steps of such a problem, summarized in the following table of contents:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Preprocessing\" data-toc-modified-id=\"Preprocessing-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Preprocessing</a></span></li><li><span><a href=\"#Data-Exploration\" data-toc-modified-id=\"Data-Exploration-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data Exploration</a></span><ul class=\"toc-item\"><li><span><a href=\"#Some-statistics-on-the-dataset\" data-toc-modified-id=\"Some-statistics-on-the-dataset-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Some statistics on the dataset</a></span></li><li><span><a href=\"#Sentiment-target-variable-analysis\" data-toc-modified-id=\"Sentiment-target-variable-analysis-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Sentiment target variable analysis</a></span></li></ul></li><li><span><a href=\"#Feature-engineering\" data-toc-modified-id=\"Feature-engineering-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Feature engineering</a></span><ul class=\"toc-item\"><li><span><a href=\"#Number-of-words\" data-toc-modified-id=\"Number-of-words-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Number of words</a></span></li><li><span><a href=\"#Counting-punctuation-(?!.)\" data-toc-modified-id=\"Counting-punctuation-(?!.)-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Counting punctuation (?!.)</a></span></li><li><span><a href=\"#Emoticons\" data-toc-modified-id=\"Emoticons-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Emoticons</a></span></li><li><span><a href=\"#Negation-words\" data-toc-modified-id=\"Negation-words-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Negation words</a></span></li><li><span><a href=\"#Sentiment-words\" data-toc-modified-id=\"Sentiment-words-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Sentiment words</a></span></li><li><span><a href=\"#Tweet2Vec\" data-toc-modified-id=\"Tweet2Vec-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>Tweet2Vec</a></span></li></ul></li><li><span><a href=\"#Models\" data-toc-modified-id=\"Models-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Stratified-k-folds\" data-toc-modified-id=\"Stratified-k-folds-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Stratified k-folds</a></span></li><li><span><a href=\"#Baseline-models\" data-toc-modified-id=\"Baseline-models-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Baseline models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Always-predicting-Neutral\" data-toc-modified-id=\"Always-predicting-Neutral-4.2.1\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>Always predicting Neutral</a></span></li><li><span><a href=\"#Predicting-randomly-following-the-distribution-of-data\" data-toc-modified-id=\"Predicting-randomly-following-the-distribution-of-data-4.2.2\"><span class=\"toc-item-num\">4.2.2&nbsp;&nbsp;</span>Predicting randomly following the distribution of data</a></span></li></ul></li><li><span><a href=\"#Random-Forest\" data-toc-modified-id=\"Random-Forest-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Random Forest</a></span><ul class=\"toc-item\"><li><span><a href=\"#Without-Tweet2Vec-features\" data-toc-modified-id=\"Without-Tweet2Vec-features-4.3.1\"><span class=\"toc-item-num\">4.3.1&nbsp;&nbsp;</span>Without Tweet2Vec features</a></span></li><li><span><a href=\"#With-Tweet2Vec-features\" data-toc-modified-id=\"With-Tweet2Vec-features-4.3.2\"><span class=\"toc-item-num\">4.3.2&nbsp;&nbsp;</span>With Tweet2Vec features</a></span></li></ul></li><li><span><a href=\"#Neural-Network\" data-toc-modified-id=\"Neural-Network-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Neural Network</a></span></li></ul></li><li><span><a href=\"#Next-steps\" data-toc-modified-id=\"Next-steps-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Next steps</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import html\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Check attached .py files for more details\n",
    "from emoticons import HAPPY, SAD, NEGATION\n",
    "from utils import detect_lang, count_emoticons, pos_score, neg_score, check_error,\\\n",
    "                                        accuracy_score_per_class\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score,\\\n",
    "                recall_score, zero_one_loss, confusion_matrix, make_scorer\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv(\"data/text_emotion_w_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 23)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (#rows, #columns)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>clean_content</th>\n",
       "      <th>lang</th>\n",
       "      <th>tknzd_tweet</th>\n",
       "      <th>length</th>\n",
       "      <th>...</th>\n",
       "      <th>nb_quest_marks</th>\n",
       "      <th>nb_emo_&lt;3</th>\n",
       "      <th>nb_emo_;)</th>\n",
       "      <th>nb_happy_emot</th>\n",
       "      <th>nb_sad_emot</th>\n",
       "      <th>nb_negation</th>\n",
       "      <th>pos_score</th>\n",
       "      <th>neg_score</th>\n",
       "      <th>pos_score_rel</th>\n",
       "      <th>neg_score_rel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>xoshayzers</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "      <td>en</td>\n",
       "      <td>['@tiffanylue', 'i', 'know', 'i', 'was', 'list...</td>\n",
       "      <td>92</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.457983</td>\n",
       "      <td>1.616071</td>\n",
       "      <td>0.025444</td>\n",
       "      <td>0.089782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>wannamama</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "      <td>layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "      <td>en</td>\n",
       "      <td>['layin', 'n', 'bed', 'with', 'a', 'headache',...</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.953125</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.073317</td>\n",
       "      <td>0.033654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>coolfunky</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "      <td>funeral ceremony...gloomy friday...</td>\n",
       "      <td>en</td>\n",
       "      <td>['funeral', 'ceremony', '...', 'gloomy', 'frid...</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.090278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>czareaquino</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "      <td>wants to hang out with friends soon!</td>\n",
       "      <td>en</td>\n",
       "      <td>['wants', 'to', 'hang', 'out', 'with', 'friend...</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.075000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>xkilljoyx</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "      <td>@dannycastillo we want to trade with someone w...</td>\n",
       "      <td>en</td>\n",
       "      <td>['@dannycastillo', 'we', 'want', 'to', 'trade'...</td>\n",
       "      <td>86</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.865179</td>\n",
       "      <td>0.777679</td>\n",
       "      <td>0.050893</td>\n",
       "      <td>0.045746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1    tweet_id   sentiment       author  \\\n",
       "0           0             0  1956967341       empty   xoshayzers   \n",
       "1           1             1  1956967666     sadness    wannamama   \n",
       "2           2             2  1956967696     sadness    coolfunky   \n",
       "3           3             3  1956967789  enthusiasm  czareaquino   \n",
       "4           4             4  1956968416     neutral    xkilljoyx   \n",
       "\n",
       "                                             content  \\\n",
       "0  @tiffanylue i know  i was listenin to bad habi...   \n",
       "1  Layin n bed with a headache  ughhhh...waitin o...   \n",
       "2                Funeral ceremony...gloomy friday...   \n",
       "3               wants to hang out with friends SOON!   \n",
       "4  @dannycastillo We want to trade with someone w...   \n",
       "\n",
       "                                       clean_content lang  \\\n",
       "0  @tiffanylue i know  i was listenin to bad habi...   en   \n",
       "1  layin n bed with a headache  ughhhh...waitin o...   en   \n",
       "2                funeral ceremony...gloomy friday...   en   \n",
       "3               wants to hang out with friends soon!   en   \n",
       "4  @dannycastillo we want to trade with someone w...   en   \n",
       "\n",
       "                                         tknzd_tweet  length      ...        \\\n",
       "0  ['@tiffanylue', 'i', 'know', 'i', 'was', 'list...      92      ...         \n",
       "1  ['layin', 'n', 'bed', 'with', 'a', 'headache',...      60      ...         \n",
       "2  ['funeral', 'ceremony', '...', 'gloomy', 'frid...      35      ...         \n",
       "3  ['wants', 'to', 'hang', 'out', 'with', 'friend...      36      ...         \n",
       "4  ['@dannycastillo', 'we', 'want', 'to', 'trade'...      86      ...         \n",
       "\n",
       "   nb_quest_marks  nb_emo_<3  nb_emo_;)  nb_happy_emot  nb_sad_emot  \\\n",
       "0               0          0          0              0            0   \n",
       "1               0          0          0              0            0   \n",
       "2               0          0          0              0            0   \n",
       "3               0          0          0              0            0   \n",
       "4               0          0          0              0            0   \n",
       "\n",
       "   nb_negation  pos_score  neg_score  pos_score_rel  neg_score_rel  \n",
       "0            1   0.457983   1.616071       0.025444       0.089782  \n",
       "1            0   0.953125   0.437500       0.073317       0.033654  \n",
       "2            0   0.500000   0.541667       0.083333       0.090278  \n",
       "3            0   0.062500   0.600000       0.007812       0.075000  \n",
       "4            1   0.865179   0.777679       0.050893       0.045746  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize first rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "In this part, we will preprocess the \"content\" column by **correcting/removing** some escape characters. Also, we will tokenize our tweets. In the Twitter context, a smart **tokenization** is required: we want to keep the emoticons and adapt to the Twitter \"slang\". Finally, we will remove **stopwords** and perform basic **stemming** on our set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Clean content column (&amp; => & | &quot; => ') and removing \"ï¿½\"\n",
    "data[\"clean_content\"] = data[\"content\"].map(lambda tweet: html.unescape(tweet).replace(\"ï¿½\", \"\").lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "tweet_tknzr = TweetTokenizer()\n",
    "data[\"tknzd_tweet\"] = data[\"clean_content\"].map(lambda tweet: tweet_tknzr.tokenize(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Removing stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "data[\"tknzd_tweet_wo_sw\"] = data[\"tknzd_tweet\"].map(lambda tknzd_tweet: [word for word in tknzd_tweet if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stemming\n",
    "ps_stemmer = PorterStemmer()\n",
    "data[\"stmd_tweet\"] = data[\"tknzd_tweet_wo_sw\"].map(lambda tknzd_tweet: [ps_stemmer.stem(word) for word in tknzd_tweet])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some statistics on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentiments = data.sentiment.unique()\n",
    "authors = data.author.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 40000 tweets, written by 33871 authors, and expressing 13 different sentiments.\n",
      "The average # of tweets per author is: 1.18\n"
     ]
    }
   ],
   "source": [
    "# Number of tweets, unique sentiments, and unique authors\n",
    "nb_tweets = data.shape[0]\n",
    "nb_sentiments = sentiments.shape[0]\n",
    "nb_authors = authors.shape[0]\n",
    "\n",
    "print(\"There are {0} tweets, written by {1} authors, and expressing {2} different \\\n",
    "sentiments.\".format(nb_tweets, nb_authors, nb_sentiments))\n",
    "print(\"The average # of tweets per author is: {:.2f}\".format(nb_tweets/nb_authors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A feature **idea** would have been to create **dummy variables** for each author: some authors may have the tendancy to express twits in a particular sentiment register. Here, the **number of authors** is **too high** and the **#tweets/author too low** for it to be a useful variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute language of each tweet\n",
    "if \"lang\" not in data.columns:\n",
    "    data[\"lang\"] = data[\"clean_content\"].map(lambda tweet: detect_lang(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a27343828>"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAE6CAYAAAD9Sp7VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2734bc18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Number of tweets per language\n",
    "nb_tweets_per_sentiment = data.groupby(\"lang\").count()[\"tweet_id\"].sort_values()\n",
    "nb_tweets_per_sentiment.plot(kind=\"bar\", title=\"Number of tweets per language\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing these numbers and for simplification, we will then consider in the following that **all tweets are in English**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: min=1, max=138, avg=72.98\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c50b7acc0>"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c5b315c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Analysis of th length of tweets\n",
    "data[\"length\"] = data[\"clean_content\"].map(lambda tweet: len(tweet))\n",
    "max_length = data.length.max()\n",
    "min_length = data.length.min()\n",
    "avg_length = data.length.mean()\n",
    "print(\"Length: min={0}, max={1}, avg={2:.2f}\".format(min_length, max_length, avg_length))\n",
    "\n",
    "data.length.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Sentiment target variable analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of possible sentiments:\n",
      "['empty' 'sadness' 'enthusiasm' 'neutral' 'worry' 'surprise' 'love' 'fun'\n",
      " 'hate' 'happiness' 'boredom' 'relief' 'anger']\n"
     ]
    }
   ],
   "source": [
    "# List of possible sentiments\n",
    "print(\"List of possible sentiments:\\n{}\".format(sentiments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c48e51390>"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAFHCAYAAACoKpuzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c399bdc18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Number of tweets per sentiment\n",
    "nb_tweets_per_sentiment = data.groupby(\"sentiment\").count()[\"tweet_id\"].sort_values()\n",
    "nb_tweets_per_sentiment.plot(kind=\"bar\", title=\"Number of tweets per sentiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiclass (13!) classification problems are tough. Moreover, classes for this problem are strongly unbalanced. To reduce this problem, I took two initiatives :\n",
    "- removing lines with \"empty\" label, that are in fact unlabeled tweets\n",
    "- moving quasi-unexisting \"anger\"-labelled tweets to \"hate\" category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Move \"anger\" category to \"hate\" category\n",
    "data[\"sentiment\"] = data[\"sentiment\"].map(lambda sentiment: \"hate\" if sentiment == \"anger\" else sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Delete empty-labelled lines\n",
    "data = data[data.sentiment != \"empty\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Feature engineering\n",
    "In this part, we will create the features that hopefully will help us to crack the sentiment analysis problem.\n",
    "\n",
    "Some classic features could be:\n",
    "- Number of **words** in the tweet\n",
    "- Punctuation: number of **exclamation marks, question marks, dots**\n",
    "- Emoticons\n",
    "- Number of negation words\n",
    "    - Number of happy and sad emoticons\n",
    "    - Number of some specific recurrent emoticons (<3, ;))\n",
    "    \n",
    "    \n",
    "Some more advanced features: \n",
    "- **Positiveness/Negativess** of a tweet using publicly available lexicon SentiWordNet\n",
    "- Tweet2Vec = aggregated Word2Vec over the words of the tweet\n",
    "\n",
    "Additional ideas:\n",
    "- *Not implemented*: use of **POS tags**, for example count of the adjectives..\n",
    "- *Not implemented*: detecting **recurrent words** per sentiment for dummy variable\n",
    "- *Not implemented*: bag-of-words model, mixed with TF-IDF\n",
    "- *Not implemented*: for the author of the tweet, count the #number of previous messages for each sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb of words: min=1, max=84, avg=15.28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c48c10860>"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfOTQWBMsgzUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c48de16a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Nb of words\n",
    "data[\"nb_words\"] = data[\"tknzd_tweet\"].map(lambda list_words: len(list_words))\n",
    "max_words = data.nb_words.max()\n",
    "min_words = data.nb_words.min()\n",
    "avg_words = data.nb_words.mean()\n",
    "print(\"Nb of words: min={0}, max={1}, avg={2:.2f}\".format(min_words, max_words, avg_words))\n",
    "\n",
    "data.nb_words.hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting punctuation (?!.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[\"nb_dots\"] = data[\"content\"].map(lambda tweet: tweet.count(\".\"))\n",
    "data[\"nb_exc_marks\"] = data[\"content\"].map(lambda tweet: tweet.count(\"!\"))\n",
    "data[\"nb_quest_marks\"] = data[\"content\"].map(lambda tweet: tweet.count(\"?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emoticons\n",
    "In emoticons.py file, we distinguinsh positive emoticons in \"HAPPY\" list, and negative emoticons in \"SAD\" list. Of course, taking into account our problem, it would have been better to have a more precise division of emoticons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_emot = HAPPY.union(SAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Count # of apparitions of emoticons in all tweets and store it in a dictionnary\n",
    "d_count = count_emoticons(data.tknzd_tweet, all_emot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'8)': 1,\n",
       " \":'(\": 32,\n",
       " \":')\": 5,\n",
       " ':-/': 10,\n",
       " ':-p': 13,\n",
       " ':@': 15,\n",
       " ':[': 7,\n",
       " ':\\\\': 9,\n",
       " ':]': 30,\n",
       " ':d': 3,\n",
       " ':o)': 2,\n",
       " ':p': 58,\n",
       " ':{': 1,\n",
       " ';(': 8,\n",
       " ';)': 191,\n",
       " '<3': 358,\n",
       " '=/': 13,\n",
       " '=\\\\': 2,\n",
       " '=]': 14,\n",
       " '=p': 14,\n",
       " 'xd': 90,\n",
       " 'xp': 6}"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For recurrent emoticons X (more than 100 occurences in dataset), \n",
    "# create a feature nb_emot_X that counts the # of X in each tweet\n",
    "recurent_threshold = 100\n",
    "# List of recurrent emoticons\n",
    "recurent_emo = [emoticon for emoticon in d_count.keys() if d_count[emoticon]>=recurent_threshold]\n",
    "\n",
    "data.drop([column for column in data.columns if \"nb_emo\" in column], axis=1, inplace=True)\n",
    "# Create the columns\n",
    "for emoticon in recurent_emo:\n",
    "    data[\"nb_emo_{}\".format(emoticon)] = data[\"tknzd_tweet\"].map(lambda words: sum([1 for word in words if word == emoticon]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Count the # of positive and negative emoticons\n",
    "data[\"nb_happy_emot\"] = data[\"tknzd_tweet\"].map(lambda words: sum([1 for word in words if word in HAPPY]))\n",
    "data[\"nb_sad_emot\"] = data[\"tknzd_tweet\"].map(lambda words: sum([1 for word in words if word in SAD]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negation words\n",
    "Count the number of negation phrases (for ex., \"cant\", \"can't\", ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[\"nb_negation\"] = data[\"clean_content\"].map(lambda tweet: sum([1 for neg_word in NEGATION if neg_word in tweet]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment words\n",
    "SentiWord net is a publicly available lexicon, giving a \"Positiveness\" and \"Negativeness\" score for each word of the english vocabulary. Our goal here is to compute a pos_score and neg_score for each tweet based on that lexicon. \n",
    "\n",
    "The idea here is, for a given tweet, to sum the scores for each word and average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sw_net = pd.read_table(\"data/swn.txt\", skiprows=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># POS</th>\n",
       "      <th>ID</th>\n",
       "      <th>PosScore</th>\n",
       "      <th>NegScore</th>\n",
       "      <th>SynsetTerms</th>\n",
       "      <th>Gloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>1740.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>able#1</td>\n",
       "      <td>(usually followed by `to') having the necessar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>2098.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>unable#1</td>\n",
       "      <td>(usually followed by `to') not having the nece...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>2312.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>dorsal#2 abaxial#1</td>\n",
       "      <td>facing away from the axis of an organ or organ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>2527.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ventral#2 adaxial#1</td>\n",
       "      <td>nearest to or facing toward the axis of an org...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>2730.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>acroscopic#1</td>\n",
       "      <td>facing or on the side toward the apex</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  # POS      ID  PosScore  NegScore          SynsetTerms  \\\n",
       "0     a  1740.0     0.125      0.00               able#1   \n",
       "1     a  2098.0     0.000      0.75             unable#1   \n",
       "2     a  2312.0     0.000      0.00   dorsal#2 abaxial#1   \n",
       "3     a  2527.0     0.000      0.00  ventral#2 adaxial#1   \n",
       "4     a  2730.0     0.000      0.00         acroscopic#1   \n",
       "\n",
       "                                               Gloss  \n",
       "0  (usually followed by `to') having the necessar...  \n",
       "1  (usually followed by `to') not having the nece...  \n",
       "2  facing away from the axis of an organ or organ...  \n",
       "3  nearest to or facing toward the axis of an org...  \n",
       "4              facing or on the side toward the apex  "
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw_net.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Sentiment words: 29095\n"
     ]
    }
   ],
   "source": [
    "# Remove objective words (ie PosScore = 0 and NegScore = 0)\n",
    "sw = sw_net[(sw_net.NegScore > 0) | (sw_net.PosScore > 0)].reset_index()\n",
    "print(\"Number of Sentiment words: {}\".format(sw.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th># POS</th>\n",
       "      <th>ID</th>\n",
       "      <th>PosScore</th>\n",
       "      <th>NegScore</th>\n",
       "      <th>SynsetTerms</th>\n",
       "      <th>Gloss</th>\n",
       "      <th>tknzd_synset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>1740.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>able#1</td>\n",
       "      <td>(usually followed by `to') having the necessar...</td>\n",
       "      <td>[able]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>2098.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>unable#1</td>\n",
       "      <td>(usually followed by `to') not having the nece...</td>\n",
       "      <td>[unable]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>a</td>\n",
       "      <td>3700.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.00</td>\n",
       "      <td>dissilient#1</td>\n",
       "      <td>bursting open with force, as do some ripe seed...</td>\n",
       "      <td>[dissilient]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>a</td>\n",
       "      <td>3829.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.00</td>\n",
       "      <td>parturient#2</td>\n",
       "      <td>giving birth; \"a parturient heifer\"</td>\n",
       "      <td>[parturient]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>a</td>\n",
       "      <td>5107.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.00</td>\n",
       "      <td>uncut#7 full-length#2</td>\n",
       "      <td>complete; \"the full-length play\"</td>\n",
       "      <td>[uncut, full-length]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index # POS      ID  PosScore  NegScore            SynsetTerms  \\\n",
       "0      0     a  1740.0     0.125      0.00                 able#1   \n",
       "1      1     a  2098.0     0.000      0.75               unable#1   \n",
       "2     10     a  3700.0     0.250      0.00           dissilient#1   \n",
       "3     11     a  3829.0     0.250      0.00           parturient#2   \n",
       "4     20     a  5107.0     0.500      0.00  uncut#7 full-length#2   \n",
       "\n",
       "                                               Gloss          tknzd_synset  \n",
       "0  (usually followed by `to') having the necessar...                [able]  \n",
       "1  (usually followed by `to') not having the nece...              [unable]  \n",
       "2  bursting open with force, as do some ripe seed...          [dissilient]  \n",
       "3                giving birth; \"a parturient heifer\"          [parturient]  \n",
       "4                   complete; \"the full-length play\"  [uncut, full-length]  "
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove \"#\" from SynsetTerms\n",
    "sw[\"tknzd_synset\"] = sw[\"SynsetTerms\"].map(lambda synset: re.sub(\"#([0-9])*\", \"\", synset).split())\n",
    "sw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg_score</th>\n",
       "      <th>pos_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>able</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unable</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dissilient</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parturient</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uncut</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            neg_score  pos_score\n",
       "able             0.00      0.125\n",
       "unable           0.75      0.000\n",
       "dissilient       0.00      0.250\n",
       "parturient       0.00      0.250\n",
       "uncut            0.00      0.500"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create usable dataframe for my computation \n",
    "word_index = []\n",
    "pos_scores = []\n",
    "neg_scores = []\n",
    "\n",
    "for i, row in sw.iterrows():\n",
    "    for word in row.tknzd_synset:\n",
    "        word_index.append(word)\n",
    "        pos_scores.append(row.PosScore)\n",
    "        neg_scores.append(row.NegScore)\n",
    "\n",
    "scores_df = pd.DataFrame(data = {\"pos_score\": pos_scores, \"neg_score\": neg_scores}, index=word_index)     \n",
    "scores_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have formatted the lexicon in the way we wanted. We can not compute pos_score and neg_score for each tweet, and then divide by the number of words to get the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[\"pos_score\"] = data[\"stmd_tweet\"].map(lambda tweet: sum([pos_score(scores_df, word) for word in tweet]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[\"neg_score\"] = data[\"stmd_tweet\"].map(lambda tweet: sum([neg_score(scores_df, word) for word in tweet]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[\"pos_score_rel\"] = data[\"pos_score\"]/data[\"nb_words\"]\n",
    "data[\"neg_score_rel\"] = data[\"neg_score\"]/data[\"nb_words\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we check the results of our created feature, by grouping the dataset by sentiment, and computing the mean of both scores. We can notice that positive sentiments have indeed a highest positive score, which makes it a good discriminating feature (same for negative sentiments and negative score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "love          0.061539\n",
       "happiness     0.054945\n",
       "relief        0.054343\n",
       "enthusiasm    0.049409\n",
       "fun           0.048912\n",
       "neutral       0.044514\n",
       "worry         0.044311\n",
       "sadness       0.043737\n",
       "surprise      0.043305\n",
       "boredom       0.041301\n",
       "hate          0.039683\n",
       "Name: pos_score_rel, dtype: float64"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(\"sentiment\").mean().sort_values(\"pos_score_rel\", ascending=False)[\"pos_score_rel\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "hate          0.048377\n",
       "sadness       0.043764\n",
       "worry         0.039564\n",
       "boredom       0.037311\n",
       "relief        0.032389\n",
       "enthusiasm    0.029139\n",
       "surprise      0.029129\n",
       "neutral       0.028207\n",
       "fun           0.028202\n",
       "happiness     0.025258\n",
       "love          0.022263\n",
       "Name: neg_score_rel, dtype: float64"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(\"sentiment\").mean().sort_values(\"neg_score_rel\", ascending=False)[\"neg_score_rel\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data.to_csv(\"data/text_emotion_w_features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweet2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we will transform each tweet to a 200 size vector. To do that, I trained a word2vec model on my tokenized tweets which outputs a vector for each word of the vocabulary. Then, we aggregate by taking the mean of all the vectors that compose the tweet.\n",
    "However, with this aggregating method, all words are considered with the same weight. In practice, all the words should not be treated equivalently, so we can weight their vector by the TF-IDF score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size_embedding = 200\n",
    "w2v_model = gensim.models.Word2Vec(data.tknzd_tweet, size=size_embedding)\n",
    "# Dict containing (key, value)=(word, vector)\n",
    "w2v = dict(zip(w2v_model.wv.index2word, w2v_model.wv.vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('miss', 0.8401534557342529),\n",
       " ('thank', 0.8305109143257141),\n",
       " ('loved', 0.7537878155708313),\n",
       " ('luv', 0.7375222444534302),\n",
       " ('owe', 0.7357692122459412),\n",
       " ('<3', 0.7205032110214233),\n",
       " ('appreciate', 0.7178507447242737),\n",
       " ('liked', 0.7169893980026245),\n",
       " ('missed', 0.7154136896133423),\n",
       " ('forgot', 0.7106112837791443)]"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check for model performance\n",
    "w2v_model.wv.most_similar(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"mother's\", 0.921486496925354),\n",
       " ('mothers', 0.8986084461212158),\n",
       " ('birthday', 0.8392003774642944),\n",
       " ('wars', 0.8318478465080261),\n",
       " ('mommys', 0.8249069452285767),\n",
       " ('beautiful', 0.8083910942077637),\n",
       " (\"momma's\", 0.8016931414604187),\n",
       " ('belated', 0.7945509552955627),\n",
       " (\"mom's\", 0.7874326705932617),\n",
       " ('mommies', 0.7732957601547241)]"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(\"happy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets2vec = []\n",
    "for index, row in data.iterrows():\n",
    "    nb_words = row.nb_words\n",
    "    tknzd_tweet = row.tknzd_tweet\n",
    "    tweet2vec = np.zeros(size_embedding)\n",
    "    # Sum the vector of each word and add them. If the word is not found, we decrease the # of words\n",
    "    for word in tknzd_tweet:\n",
    "        try:\n",
    "            tweet2vec += w2v[word]\n",
    "        except KeyError:\n",
    "            if nb_words > 1:\n",
    "                nb_words -= 1\n",
    "    # Divide by number of words\n",
    "    tweet2vec /= nb_words\n",
    "    tweets2vec.append(tweet2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t2v_0</th>\n",
       "      <th>t2v_1</th>\n",
       "      <th>t2v_2</th>\n",
       "      <th>t2v_3</th>\n",
       "      <th>t2v_4</th>\n",
       "      <th>t2v_5</th>\n",
       "      <th>t2v_6</th>\n",
       "      <th>t2v_7</th>\n",
       "      <th>t2v_8</th>\n",
       "      <th>t2v_9</th>\n",
       "      <th>...</th>\n",
       "      <th>t2v_190</th>\n",
       "      <th>t2v_191</th>\n",
       "      <th>t2v_192</th>\n",
       "      <th>t2v_193</th>\n",
       "      <th>t2v_194</th>\n",
       "      <th>t2v_195</th>\n",
       "      <th>t2v_196</th>\n",
       "      <th>t2v_197</th>\n",
       "      <th>t2v_198</th>\n",
       "      <th>t2v_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.217394</td>\n",
       "      <td>0.144365</td>\n",
       "      <td>0.026492</td>\n",
       "      <td>-0.085305</td>\n",
       "      <td>-0.036387</td>\n",
       "      <td>-0.094769</td>\n",
       "      <td>0.083103</td>\n",
       "      <td>0.286269</td>\n",
       "      <td>0.087822</td>\n",
       "      <td>0.077326</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.149738</td>\n",
       "      <td>0.144362</td>\n",
       "      <td>0.239027</td>\n",
       "      <td>0.166448</td>\n",
       "      <td>-0.058622</td>\n",
       "      <td>0.277699</td>\n",
       "      <td>-0.384980</td>\n",
       "      <td>0.270411</td>\n",
       "      <td>0.072929</td>\n",
       "      <td>-0.237130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.068037</td>\n",
       "      <td>0.015649</td>\n",
       "      <td>-0.001767</td>\n",
       "      <td>-0.137875</td>\n",
       "      <td>0.029204</td>\n",
       "      <td>-0.139645</td>\n",
       "      <td>0.081710</td>\n",
       "      <td>0.133905</td>\n",
       "      <td>0.099852</td>\n",
       "      <td>-0.007356</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034437</td>\n",
       "      <td>0.049678</td>\n",
       "      <td>0.172862</td>\n",
       "      <td>0.109237</td>\n",
       "      <td>-0.039397</td>\n",
       "      <td>0.162186</td>\n",
       "      <td>-0.224083</td>\n",
       "      <td>0.081859</td>\n",
       "      <td>0.027599</td>\n",
       "      <td>-0.144734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.481586</td>\n",
       "      <td>0.263456</td>\n",
       "      <td>-0.098936</td>\n",
       "      <td>-0.230188</td>\n",
       "      <td>-0.086499</td>\n",
       "      <td>-0.040481</td>\n",
       "      <td>-0.011437</td>\n",
       "      <td>0.314480</td>\n",
       "      <td>-0.071701</td>\n",
       "      <td>0.049454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061767</td>\n",
       "      <td>-0.009299</td>\n",
       "      <td>0.061778</td>\n",
       "      <td>0.187102</td>\n",
       "      <td>0.102376</td>\n",
       "      <td>0.272907</td>\n",
       "      <td>-0.555231</td>\n",
       "      <td>0.470309</td>\n",
       "      <td>-0.097704</td>\n",
       "      <td>-0.345757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.239376</td>\n",
       "      <td>0.169543</td>\n",
       "      <td>0.036071</td>\n",
       "      <td>0.056422</td>\n",
       "      <td>-0.211502</td>\n",
       "      <td>-0.067794</td>\n",
       "      <td>0.111140</td>\n",
       "      <td>0.163457</td>\n",
       "      <td>0.056772</td>\n",
       "      <td>0.016451</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.123575</td>\n",
       "      <td>-0.172463</td>\n",
       "      <td>0.349211</td>\n",
       "      <td>0.335293</td>\n",
       "      <td>0.071826</td>\n",
       "      <td>0.374123</td>\n",
       "      <td>-0.501034</td>\n",
       "      <td>0.340120</td>\n",
       "      <td>0.008684</td>\n",
       "      <td>-0.355157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.313063</td>\n",
       "      <td>0.317073</td>\n",
       "      <td>0.109620</td>\n",
       "      <td>0.038170</td>\n",
       "      <td>-0.327444</td>\n",
       "      <td>-0.134137</td>\n",
       "      <td>0.008147</td>\n",
       "      <td>0.393080</td>\n",
       "      <td>0.111889</td>\n",
       "      <td>0.027864</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.344380</td>\n",
       "      <td>0.102595</td>\n",
       "      <td>0.445854</td>\n",
       "      <td>0.235502</td>\n",
       "      <td>0.029792</td>\n",
       "      <td>0.205163</td>\n",
       "      <td>-0.396248</td>\n",
       "      <td>0.308946</td>\n",
       "      <td>0.016970</td>\n",
       "      <td>-0.302793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      t2v_0     t2v_1     t2v_2     t2v_3     t2v_4     t2v_5     t2v_6  \\\n",
       "0  0.217394  0.144365  0.026492 -0.085305 -0.036387 -0.094769  0.083103   \n",
       "1  0.068037  0.015649 -0.001767 -0.137875  0.029204 -0.139645  0.081710   \n",
       "2  0.481586  0.263456 -0.098936 -0.230188 -0.086499 -0.040481 -0.011437   \n",
       "3  0.239376  0.169543  0.036071  0.056422 -0.211502 -0.067794  0.111140   \n",
       "4  0.313063  0.317073  0.109620  0.038170 -0.327444 -0.134137  0.008147   \n",
       "\n",
       "      t2v_7     t2v_8     t2v_9    ...      t2v_190   t2v_191   t2v_192  \\\n",
       "0  0.286269  0.087822  0.077326    ...    -0.149738  0.144362  0.239027   \n",
       "1  0.133905  0.099852 -0.007356    ...    -0.034437  0.049678  0.172862   \n",
       "2  0.314480 -0.071701  0.049454    ...     0.061767 -0.009299  0.061778   \n",
       "3  0.163457  0.056772  0.016451    ...    -0.123575 -0.172463  0.349211   \n",
       "4  0.393080  0.111889  0.027864    ...    -0.344380  0.102595  0.445854   \n",
       "\n",
       "    t2v_193   t2v_194   t2v_195   t2v_196   t2v_197   t2v_198   t2v_199  \n",
       "0  0.166448 -0.058622  0.277699 -0.384980  0.270411  0.072929 -0.237130  \n",
       "1  0.109237 -0.039397  0.162186 -0.224083  0.081859  0.027599 -0.144734  \n",
       "2  0.187102  0.102376  0.272907 -0.555231  0.470309 -0.097704 -0.345757  \n",
       "3  0.335293  0.071826  0.374123 -0.501034  0.340120  0.008684 -0.355157  \n",
       "4  0.235502  0.029792  0.205163 -0.396248  0.308946  0.016970 -0.302793  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2v = pd.DataFrame(tweets2vec, columns=[\"t2v_{}\".format(i) for i in range(size_embedding)])\n",
    "t2v.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "In this part, there will be 3 challenges:\n",
    "1. Because of the unbalanced classes, we have to find the correct way to split between train and cross-validation set We will use **Stratified k-fold** from scikit-learn library to preserve the percentage of samples for each class.\n",
    "2. We must define correctly the **metric that we want to optimize**, even more because we have a multi-class classification problem.\n",
    "3. We should define some **baseline \"dummy\" models** to be able to quantify the improvement (or no) of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = [\"length\", \"pos_score_rel\", \"neg_score_rel\"] + [column for column in data.columns if \"nb_\" in column]\n",
    "X = data[features]\n",
    "y = data.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_sent: {'sadness': 0, 'enthusiasm': 1, 'neutral': 2, 'worry': 3, 'surprise': 4, 'love': 5, 'fun': 6, 'hate': 7, 'happiness': 8, 'boredom': 9, 'relief': 10}\n",
      "inv_d_sent: {0: 'sadness', 1: 'enthusiasm', 2: 'neutral', 3: 'worry', 4: 'surprise', 5: 'love', 6: 'fun', 7: 'hate', 8: 'happiness', 9: 'boredom', 10: 'relief'}\n"
     ]
    }
   ],
   "source": [
    "# The following dictionnaries assign each sentiment to a label \n",
    "# from 0 to 10 and will be used to get from a label to the sentiment\n",
    "d_sent = {}\n",
    "sent_index = 0\n",
    "for sentiment in y.unique():\n",
    "    d_sent[sentiment] = sent_index\n",
    "    sent_index += 1\n",
    "\n",
    "inv_d_sent = {}\n",
    "for sentiment in y.unique():\n",
    "    inv_d_sent[d_sent[sentiment]] = sentiment\n",
    "    \n",
    "print(\"d_sent: {}\".format(d_sent))\n",
    "print(\"inv_d_sent: {}\".format(inv_d_sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentionned before, we have a highly unbalanced multi-class classification problem. The following table shows the proportion of each sentiment in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "neutral       22.050902\n",
       "worry         21.593955\n",
       "happiness     13.297424\n",
       "sadness       13.185102\n",
       "love           9.807776\n",
       "surprise       5.582927\n",
       "fun            4.533735\n",
       "relief         3.895540\n",
       "hate           3.658132\n",
       "enthusiasm     1.937559\n",
       "boredom        0.456947\n",
       "Name: tweet_id, dtype: float64"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((data.groupby(\"sentiment\").count()[\"tweet_id\"]/data.shape[0]).sort_values(ascending=False))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Stratified k-folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to quantify correctly the improvements of the algorithm, we have to be able to test it over a cross-validation set. This cross-validation set should be a good representation of the entire dataset, hence random sampling is not acceptable. That is why we are usign a stratified k-fold that allow us to keep in the train and test sets the same proportion of sentiments as in the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(4)\n",
    "train, test = next(skf.split(X,y))\n",
    "\n",
    "X_train = X.loc[train]\n",
    "y_train = y[train]\n",
    "\n",
    "X_test = X.loc[test]\n",
    "y_test = y[test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                index\n",
      "sentiment            \n",
      "neutral     22.052766\n",
      "worry       21.596596\n",
      "happiness   13.297021\n",
      "sadness     13.184681\n",
      "love         9.807660\n",
      "surprise     5.582979\n",
      "fun          4.534468\n",
      "relief       3.894468\n",
      "hate         3.656170\n",
      "enthusiasm   1.937021\n",
      "boredom      0.456170\n"
     ]
    }
   ],
   "source": [
    "# To show that proportions are indeed kept\n",
    "print(((pd.DataFrame(y_train).reset_index().groupby(\"sentiment\").count()/y_train.shape[0]).sort_values(by=\"index\", ascending=False))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Baseline models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worth mentionning that the metric of quality is of high importance here due to the nature of the problem. The relevant metric to consider is strongly correlated with the business application. Here, we will keep track of the **micro and macro averages of the accuracy**, but other possibilities (precision, recall) could be accepted.\n",
    "\n",
    "We will try 2 baseline models to be able to quantify the performance of future models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Always predicting Neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neutral index is 3\n",
    "y_true = y.map(d_sent)\n",
    "y_pred = np.array([3]*data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro-average accuracy: 21.6%\n",
      "Micro-average accuracy: 9.1%\n",
      "#####\n",
      "     sentiment  accuracy\n",
      "0      sadness       0.0\n",
      "1   enthusiasm       0.0\n",
      "2      neutral       0.0\n",
      "3        worry     100.0\n",
      "4     surprise       0.0\n",
      "5         love       0.0\n",
      "6          fun       0.0\n",
      "7         hate       0.0\n",
      "8    happiness       0.0\n",
      "9      boredom       0.0\n",
      "10      relief       0.0\n"
     ]
    }
   ],
   "source": [
    "accuracies = accuracy_score_per_class(y_true, y_pred, inv_d_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always predicting \"neutral\" leads to a 22% macro-average accuracy, and is more penalized by the micro-average which considers evenly each sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Accuracy: {:.2}\".format(accuracy_score(y.map(d_sent), y_pred)))\n",
    "#print(\"Recall: {:.2}\".format(recall_score(y.map(d_sent), y_pred, average = \"macro\")))\n",
    "#print(\"Precision: {:.2}\".format(precision_score(y.map(d_sent), y_pred, average = \"macro\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting randomly following the distribution of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvals = [0]*13\n",
    "for sentiment in d_sent.keys():\n",
    "    index = d_sent[sentiment]\n",
    "    pval = data.groupby(\"sentiment\").count()[\"tweet_id\"][sentiment]\n",
    "    pvals[index] = pval/data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = [np.argmax(draw) for draw in np.random.multinomial(1, pvals, size=data.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro-average accuracy: 14.6%\n",
      "Micro-average accuracy: 9.0%\n",
      "#####\n",
      "     sentiment  accuracy\n",
      "0      sadness      11.8\n",
      "1   enthusiasm       2.2\n",
      "2      neutral      21.5\n",
      "3        worry      21.6\n",
      "4     surprise       4.4\n",
      "5         love      10.0\n",
      "6          fun       4.5\n",
      "7         hate       4.5\n",
      "8    happiness      13.6\n",
      "9      boredom       0.6\n",
      "10      relief       4.6\n"
     ]
    }
   ],
   "source": [
    "accuracies = accuracy_score_per_class(y_true, y_pred, inv_d_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(\"Accuracy: {:.2}\".format(accuracy_score(y.map(d_sent), y_pred)))\n",
    "#print(\"Recall: {:.2}\".format(recall_score(y.map(d_sent), y_pred, average = \"macro\")))\n",
    "#print(\"Precision: {:.2}\".format(precision_score(y.map(d_sent), y_pred, average = \"macro\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without Tweet2Vec features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = next(skf.split(X,y))\n",
    "\n",
    "X_train = X.loc[train]\n",
    "y_train = y[train]\n",
    "\n",
    "X_test = X.loc[test]\n",
    "y_test = y[test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, max_depth=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "y_true = y_test.map(d_sent).reset_index()[\"sentiment\"]\n",
    "y_pred = pd.Series(clf.predict(X_test)).map(d_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro-average accuracy: 28.5%\n",
      "Micro-average accuracy: 13.0%\n",
      "#####\n",
      "     sentiment  accuracy\n",
      "0      sadness       1.9\n",
      "1   enthusiasm       0.0\n",
      "2      neutral      47.3\n",
      "3        worry      66.3\n",
      "4     surprise       0.4\n",
      "5         love       4.6\n",
      "6          fun       0.0\n",
      "7         hate       0.0\n",
      "8    happiness      22.8\n",
      "9      boredom       0.0\n",
      "10      relief       0.0\n"
     ]
    }
   ],
   "source": [
    "accuracies = accuracy_score_per_class(y_true, y_pred, inv_d_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the micro and macro average accuracies are improved only a bit, the algorithm seems to be more able to detect classes for which we have more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                importance\n",
      "neg_score_rel     0.245374\n",
      "pos_score_rel     0.192427\n",
      "length            0.145127\n",
      "nb_words          0.132593\n",
      "nb_exc_marks      0.102270\n",
      "nb_dots           0.059793\n",
      "nb_negation       0.058053\n",
      "nb_quest_marks    0.035755\n",
      "nb_happy_emot     0.012388\n",
      "nb_emo_<3         0.008797\n"
     ]
    }
   ],
   "source": [
    "feature_importance = pd.DataFrame(clf.feature_importances_, index=X.columns, columns=[\"importance\"]).sort_values(by=\"importance\", ascending=False)\n",
    "print(feature_importance[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us know that neg_score and pos_score are good features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "#macro_precision_scorer = make_scorer(precision_score, average=\"macro\")\n",
    "#macro_recall_scorer = make_scorer(recall_score, average=\"macro\")\n",
    "#\n",
    "#accuracies = cross_val_score(clf, X, y, cv=skf.split(X,y))\n",
    "#precisions = cross_val_score(clf, X, y, cv=skf.split(X,y), scoring=macro_precision_scorer)\n",
    "#recalls = cross_val_score(clf, X, y, cv=skf.split(X,y), scoring=macro_recall_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(\"Accuracy: {:.2}\".format(accuracies.mean()))\n",
    "#print(\"Recall: {:.2}\".format(recalls.mean()))\n",
    "#print(\"Precision: {:.2}\".format(precisions.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Tweet2Vec features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39173, 212)"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t2v = X.join(t2v)\n",
    "X_t2v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = next(skf.split(X_t2v, y))\n",
    "\n",
    "X_train = X_t2v.loc[train]\n",
    "y_train = y[train].map(d_sent)\n",
    "\n",
    "X_test = X_t2v.loc[test]\n",
    "y_test = y[test].map(d_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "y_true = y_test.reset_index()[\"sentiment\"]\n",
    "y_pred = pd.Series(clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro-average accuracy: 28.3%\n",
      "Micro-average accuracy: 12.9%\n",
      "#####\n",
      "     sentiment  accuracy\n",
      "0      sadness       1.4\n",
      "1   enthusiasm       0.0\n",
      "2      neutral      43.8\n",
      "3        worry      71.2\n",
      "4     surprise       0.0\n",
      "5         love       6.9\n",
      "6          fun       0.0\n",
      "7         hate       0.0\n",
      "8    happiness      18.6\n",
      "9      boredom       0.0\n",
      "10      relief       0.0\n"
     ]
    }
   ],
   "source": [
    "accuracies = accuracy_score_per_class(y_true, y_pred, inv_d_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               importance\n",
      "neg_score_rel    0.030666\n",
      "t2v_83           0.019633\n",
      "t2v_2            0.017413\n",
      "nb_words         0.014805\n",
      "pos_score_rel    0.012517\n",
      "length           0.012380\n",
      "t2v_13           0.011694\n",
      "t2v_48           0.011186\n",
      "t2v_31           0.010272\n",
      "t2v_130          0.009928\n"
     ]
    }
   ],
   "source": [
    "feature_importance = pd.DataFrame(clf.feature_importances_, index=X_t2v.columns, columns=[\"importance\"]).sort_values(by=\"importance\", ascending=False)\n",
    "print(feature_importance[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracies = cross_val_score(clf, X_t2v, y, cv=skf.split(X_t2v,y))\n",
    "#precisions = cross_val_score(clf, X_t2v, y, cv=skf.split(X_t2v,y), scoring=macro_precision_scorer)\n",
    "#recalls = cross_val_score(clf, X_t2v, y, cv=skf.split(X_t2v,y), scoring=macro_recall_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Accuracy: {:.2}\".format(accuracies.mean()))\n",
    "#print(\"Recall: {:.2}\".format(recalls.mean()))\n",
    "#print(\"Precision: {:.2}\".format(precisions.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network\n",
    "Neural networks intent to check if there is a significant improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = next(skf.split(X_t2v, y))\n",
    "\n",
    "X_train = X_t2v.loc[train]\n",
    "y_train = to_categorical(y[train].map(d_sent))\n",
    "\n",
    "X_test = X_t2v.loc[test]\n",
    "y_test = to_categorical(y[test].map(d_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (29375, 212)\n",
      "y_train shape: (29375, 11)\n",
      "X_test shape: (9798, 212)\n",
      "y_test shape: (9798, 11)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape: {}\".format(X_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))\n",
    "print(\"X_test shape: {}\".format(X_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def two_hidden_layers(input_dim, output_dim, nb_n1, nb_n2, nb_n3):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(nb_n1, input_dim=input_dim, activation=\"relu\"))\n",
    "    # Normalization layer\n",
    "    model.add(BatchNormalization())\n",
    "    # Prevent overfitting \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_n2, input_dim=input_dim, activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_n2, input_dim=input_dim, activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_dim, activation=\"softmax\"))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=\"adam\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 29375 samples, validate on 9798 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 2.2949 - acc: 0.1942 - val_loss: 2.1127 - val_acc: 0.2424\n",
      "Epoch 2/100\n",
      " - 1s - loss: 2.1215 - acc: 0.2289 - val_loss: 2.0676 - val_acc: 0.2492\n",
      "Epoch 3/100\n",
      " - 1s - loss: 2.0761 - acc: 0.2466 - val_loss: 2.0593 - val_acc: 0.2588\n",
      "Epoch 4/100\n",
      " - 1s - loss: 2.0481 - acc: 0.2601 - val_loss: 2.0597 - val_acc: 0.2468\n",
      "Epoch 5/100\n",
      " - 1s - loss: 2.0347 - acc: 0.2683 - val_loss: 2.0585 - val_acc: 0.2511\n",
      "Epoch 6/100\n",
      " - 1s - loss: 2.0207 - acc: 0.2748 - val_loss: 2.0365 - val_acc: 0.2701\n",
      "Epoch 7/100\n",
      " - 1s - loss: 2.0150 - acc: 0.2769 - val_loss: 2.0289 - val_acc: 0.2672\n",
      "Epoch 8/100\n",
      " - 1s - loss: 2.0055 - acc: 0.2814 - val_loss: 2.0249 - val_acc: 0.2775\n",
      "Epoch 9/100\n",
      " - 1s - loss: 1.9987 - acc: 0.2863 - val_loss: 2.0216 - val_acc: 0.2694\n",
      "Epoch 10/100\n",
      " - 1s - loss: 1.9912 - acc: 0.2885 - val_loss: 2.0320 - val_acc: 0.2708\n",
      "Epoch 11/100\n",
      " - 1s - loss: 1.9924 - acc: 0.2881 - val_loss: 2.0372 - val_acc: 0.2617\n",
      "Epoch 12/100\n",
      " - 1s - loss: 1.9820 - acc: 0.2928 - val_loss: 2.0132 - val_acc: 0.2766\n",
      "Epoch 13/100\n",
      " - 1s - loss: 1.9786 - acc: 0.2954 - val_loss: 2.0036 - val_acc: 0.2822\n",
      "Epoch 14/100\n",
      " - 1s - loss: 1.9767 - acc: 0.2937 - val_loss: 2.0326 - val_acc: 0.2669\n",
      "Epoch 15/100\n",
      " - 1s - loss: 1.9693 - acc: 0.2995 - val_loss: 2.0055 - val_acc: 0.2810\n",
      "Epoch 16/100\n",
      " - 1s - loss: 1.9680 - acc: 0.2947 - val_loss: 2.0804 - val_acc: 0.2667\n",
      "Epoch 17/100\n",
      " - 1s - loss: 1.9653 - acc: 0.2991 - val_loss: 2.0009 - val_acc: 0.2858\n",
      "Epoch 18/100\n",
      " - 1s - loss: 1.9614 - acc: 0.3019 - val_loss: 1.9951 - val_acc: 0.2897\n",
      "Epoch 19/100\n",
      " - 1s - loss: 1.9636 - acc: 0.3004 - val_loss: 2.0077 - val_acc: 0.2841\n",
      "Epoch 20/100\n",
      " - 1s - loss: 1.9659 - acc: 0.3015 - val_loss: 2.0062 - val_acc: 0.2783\n",
      "Epoch 21/100\n",
      " - 1s - loss: 1.9578 - acc: 0.3009 - val_loss: 2.0002 - val_acc: 0.2834\n",
      "Epoch 22/100\n",
      " - 1s - loss: 1.9551 - acc: 0.3025 - val_loss: 2.0496 - val_acc: 0.2645\n",
      "Epoch 23/100\n",
      " - 1s - loss: 1.9565 - acc: 0.3062 - val_loss: 2.0675 - val_acc: 0.2701\n",
      "Epoch 24/100\n",
      " - 1s - loss: 1.9511 - acc: 0.3075 - val_loss: 2.0029 - val_acc: 0.2778\n",
      "Epoch 25/100\n",
      " - 1s - loss: 1.9481 - acc: 0.3079 - val_loss: 2.0296 - val_acc: 0.2735\n",
      "Epoch 26/100\n",
      " - 1s - loss: 1.9506 - acc: 0.3044 - val_loss: 2.0395 - val_acc: 0.2619\n",
      "Epoch 27/100\n",
      " - 1s - loss: 1.9473 - acc: 0.3080 - val_loss: 2.0047 - val_acc: 0.2822\n",
      "Epoch 28/100\n",
      " - 1s - loss: 1.9452 - acc: 0.3086 - val_loss: 1.9933 - val_acc: 0.2894\n",
      "Epoch 29/100\n",
      " - 1s - loss: 1.9430 - acc: 0.3094 - val_loss: 1.9915 - val_acc: 0.2923\n",
      "Epoch 30/100\n",
      " - 1s - loss: 1.9407 - acc: 0.3094 - val_loss: 1.9839 - val_acc: 0.2940\n",
      "Epoch 31/100\n",
      " - 1s - loss: 1.9405 - acc: 0.3086 - val_loss: 2.0008 - val_acc: 0.2856\n",
      "Epoch 32/100\n",
      " - 1s - loss: 1.9400 - acc: 0.3108 - val_loss: 2.0291 - val_acc: 0.2771\n",
      "Epoch 33/100\n",
      " - 1s - loss: 1.9416 - acc: 0.3079 - val_loss: 2.0525 - val_acc: 0.2726\n",
      "Epoch 34/100\n",
      " - 1s - loss: 1.9391 - acc: 0.3108 - val_loss: 2.0710 - val_acc: 0.2648\n",
      "Epoch 35/100\n",
      " - 1s - loss: 1.9389 - acc: 0.3142 - val_loss: 1.9841 - val_acc: 0.2931\n",
      "Epoch 36/100\n",
      " - 1s - loss: 1.9375 - acc: 0.3139 - val_loss: 2.0846 - val_acc: 0.2654\n",
      "Epoch 37/100\n",
      " - 1s - loss: 1.9366 - acc: 0.3134 - val_loss: 2.0030 - val_acc: 0.2882\n",
      "Epoch 38/100\n",
      " - 1s - loss: 1.9391 - acc: 0.3105 - val_loss: 1.9827 - val_acc: 0.2963\n",
      "Epoch 39/100\n",
      " - 1s - loss: 1.9356 - acc: 0.3129 - val_loss: 2.0069 - val_acc: 0.2859\n",
      "Epoch 40/100\n",
      " - 1s - loss: 1.9325 - acc: 0.3138 - val_loss: 1.9935 - val_acc: 0.2904\n",
      "Epoch 41/100\n",
      " - 1s - loss: 1.9328 - acc: 0.3156 - val_loss: 2.0009 - val_acc: 0.2915\n",
      "Epoch 42/100\n",
      " - 1s - loss: 1.9325 - acc: 0.3144 - val_loss: 1.9773 - val_acc: 0.2956\n",
      "Epoch 43/100\n",
      " - 1s - loss: 1.9304 - acc: 0.3177 - val_loss: 1.9878 - val_acc: 0.2872\n",
      "Epoch 44/100\n",
      " - 1s - loss: 1.9313 - acc: 0.3138 - val_loss: 1.9763 - val_acc: 0.3002\n",
      "Epoch 45/100\n",
      " - 1s - loss: 1.9305 - acc: 0.3185 - val_loss: 2.0162 - val_acc: 0.2898\n",
      "Epoch 46/100\n",
      " - 1s - loss: 1.9322 - acc: 0.3176 - val_loss: 1.9956 - val_acc: 0.2959\n",
      "Epoch 47/100\n",
      " - 1s - loss: 1.9297 - acc: 0.3183 - val_loss: 1.9961 - val_acc: 0.2948\n",
      "Epoch 48/100\n",
      " - 1s - loss: 1.9288 - acc: 0.3153 - val_loss: 1.9871 - val_acc: 0.2996\n",
      "Epoch 49/100\n",
      " - 1s - loss: 1.9310 - acc: 0.3169 - val_loss: 1.9705 - val_acc: 0.3029\n",
      "Epoch 50/100\n",
      " - 1s - loss: 1.9299 - acc: 0.3140 - val_loss: 2.0405 - val_acc: 0.2716\n",
      "Epoch 51/100\n",
      " - 1s - loss: 1.9311 - acc: 0.3128 - val_loss: 1.9960 - val_acc: 0.2927\n",
      "Epoch 52/100\n",
      " - 1s - loss: 1.9309 - acc: 0.3127 - val_loss: 1.9796 - val_acc: 0.3004\n",
      "Epoch 53/100\n",
      " - 1s - loss: 1.9322 - acc: 0.3167 - val_loss: 2.0435 - val_acc: 0.2705\n",
      "Epoch 54/100\n",
      " - 1s - loss: 1.9267 - acc: 0.3193 - val_loss: 1.9875 - val_acc: 0.2953\n",
      "Epoch 55/100\n",
      " - 1s - loss: 1.9281 - acc: 0.3181 - val_loss: 2.0032 - val_acc: 0.2842\n",
      "Epoch 56/100\n",
      " - 1s - loss: 1.9275 - acc: 0.3164 - val_loss: 1.9848 - val_acc: 0.2963\n",
      "Epoch 57/100\n",
      " - 1s - loss: 1.9296 - acc: 0.3156 - val_loss: 1.9888 - val_acc: 0.2965\n",
      "Epoch 58/100\n",
      " - 1s - loss: 1.9280 - acc: 0.3201 - val_loss: 1.9814 - val_acc: 0.2966\n",
      "Epoch 59/100\n",
      " - 1s - loss: 1.9309 - acc: 0.3156 - val_loss: 1.9754 - val_acc: 0.3029\n",
      "Epoch 60/100\n",
      " - 1s - loss: 1.9313 - acc: 0.3167 - val_loss: 1.9807 - val_acc: 0.3002\n",
      "Epoch 61/100\n",
      " - 1s - loss: 1.9284 - acc: 0.3161 - val_loss: 2.0116 - val_acc: 0.2870\n",
      "Epoch 62/100\n",
      " - 1s - loss: 1.9278 - acc: 0.3187 - val_loss: 1.9739 - val_acc: 0.2992\n",
      "Epoch 63/100\n",
      " - 1s - loss: 1.9272 - acc: 0.3164 - val_loss: 2.0169 - val_acc: 0.2831\n",
      "Epoch 64/100\n",
      " - 1s - loss: 1.9246 - acc: 0.3197 - val_loss: 1.9693 - val_acc: 0.3031\n",
      "Epoch 65/100\n",
      " - 1s - loss: 1.9256 - acc: 0.3189 - val_loss: 1.9743 - val_acc: 0.3011\n",
      "Epoch 66/100\n",
      " - 1s - loss: 1.9248 - acc: 0.3164 - val_loss: 1.9782 - val_acc: 0.2982\n",
      "Epoch 67/100\n",
      " - 1s - loss: 1.9230 - acc: 0.3183 - val_loss: 2.0259 - val_acc: 0.2862\n",
      "Epoch 68/100\n",
      " - 1s - loss: 1.9250 - acc: 0.3175 - val_loss: 1.9799 - val_acc: 0.3010\n",
      "Epoch 69/100\n",
      " - 1s - loss: 1.9245 - acc: 0.3200 - val_loss: 1.9796 - val_acc: 0.2974\n",
      "Epoch 70/100\n",
      " - 1s - loss: 1.9250 - acc: 0.3199 - val_loss: 2.0163 - val_acc: 0.2895\n",
      "Epoch 71/100\n",
      " - 1s - loss: 1.9229 - acc: 0.3217 - val_loss: 2.0022 - val_acc: 0.2909\n",
      "Epoch 72/100\n",
      " - 1s - loss: 1.9255 - acc: 0.3189 - val_loss: 1.9923 - val_acc: 0.2932\n",
      "Epoch 73/100\n",
      " - 1s - loss: 1.9264 - acc: 0.3188 - val_loss: 1.9923 - val_acc: 0.2938\n",
      "Epoch 74/100\n",
      " - 1s - loss: 1.9231 - acc: 0.3192 - val_loss: 2.0422 - val_acc: 0.2745\n",
      "Epoch 75/100\n",
      " - 1s - loss: 1.9241 - acc: 0.3200 - val_loss: 2.0351 - val_acc: 0.2846\n",
      "Epoch 76/100\n",
      " - 1s - loss: 1.9247 - acc: 0.3183 - val_loss: 2.0932 - val_acc: 0.2706\n",
      "Epoch 77/100\n",
      " - 1s - loss: 1.9240 - acc: 0.3182 - val_loss: 1.9999 - val_acc: 0.2921\n",
      "Epoch 78/100\n",
      " - 1s - loss: 1.9229 - acc: 0.3222 - val_loss: 2.0513 - val_acc: 0.2796\n",
      "Epoch 79/100\n",
      " - 1s - loss: 1.9215 - acc: 0.3186 - val_loss: 1.9920 - val_acc: 0.2931\n",
      "Epoch 80/100\n",
      " - 1s - loss: 1.9209 - acc: 0.3210 - val_loss: 1.9873 - val_acc: 0.2981\n",
      "Epoch 81/100\n",
      " - 1s - loss: 1.9190 - acc: 0.3250 - val_loss: 1.9756 - val_acc: 0.3010\n",
      "Epoch 82/100\n",
      " - 1s - loss: 1.9237 - acc: 0.3193 - val_loss: 1.9787 - val_acc: 0.3018\n",
      "Epoch 83/100\n",
      " - 1s - loss: 1.9210 - acc: 0.3224 - val_loss: 1.9850 - val_acc: 0.2989\n",
      "Epoch 84/100\n",
      " - 1s - loss: 1.9193 - acc: 0.3203 - val_loss: 1.9881 - val_acc: 0.2978\n",
      "Epoch 85/100\n",
      " - 1s - loss: 1.9218 - acc: 0.3221 - val_loss: 1.9871 - val_acc: 0.2950\n",
      "Epoch 86/100\n",
      " - 1s - loss: 1.9166 - acc: 0.3231 - val_loss: 2.0245 - val_acc: 0.2875\n",
      "Epoch 87/100\n",
      " - 1s - loss: 1.9191 - acc: 0.3224 - val_loss: 2.0299 - val_acc: 0.2860\n",
      "Epoch 88/100\n",
      " - 1s - loss: 1.9206 - acc: 0.3197 - val_loss: 1.9973 - val_acc: 0.2943\n",
      "Epoch 89/100\n",
      " - 1s - loss: 1.9187 - acc: 0.3212 - val_loss: 1.9757 - val_acc: 0.2990\n",
      "Epoch 90/100\n",
      " - 1s - loss: 1.9179 - acc: 0.3230 - val_loss: 2.0230 - val_acc: 0.2885\n",
      "Epoch 91/100\n",
      " - 2s - loss: 1.9185 - acc: 0.3224 - val_loss: 2.0140 - val_acc: 0.2895\n",
      "Epoch 92/100\n",
      " - 2s - loss: 1.9148 - acc: 0.3241 - val_loss: 2.0260 - val_acc: 0.2882\n",
      "Epoch 93/100\n",
      " - 1s - loss: 1.9213 - acc: 0.3217 - val_loss: 1.9907 - val_acc: 0.2939\n",
      "Epoch 94/100\n",
      " - 1s - loss: 1.9166 - acc: 0.3214 - val_loss: 1.9746 - val_acc: 0.3044\n",
      "Epoch 95/100\n",
      " - 1s - loss: 1.9156 - acc: 0.3244 - val_loss: 1.9746 - val_acc: 0.2985\n",
      "Epoch 96/100\n",
      " - 1s - loss: 1.9192 - acc: 0.3226 - val_loss: 1.9766 - val_acc: 0.2927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      " - 1s - loss: 1.9186 - acc: 0.3193 - val_loss: 2.0160 - val_acc: 0.2863\n",
      "Epoch 98/100\n",
      " - 1s - loss: 1.9150 - acc: 0.3244 - val_loss: 1.9912 - val_acc: 0.2926\n",
      "Epoch 99/100\n",
      " - 1s - loss: 1.9148 - acc: 0.3253 - val_loss: 2.0138 - val_acc: 0.2890\n",
      "Epoch 100/100\n",
      " - 1s - loss: 1.9165 - acc: 0.3228 - val_loss: 1.9645 - val_acc: 0.3049\n"
     ]
    }
   ],
   "source": [
    "model = two_hidden_layers(X_train.shape[1], y_train.shape[1], 100, 50, 25)\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=126, \n",
    "                    validation_data = (X_test, y_test),\n",
    "                    epochs=100, \n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The macro-average accuracy is around 29%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6uJAYmZmdXEgMTOzuvw/WCp3v+NQlBEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c468c13c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summarize history for loss\n",
    "plt.plot(history.history[\"acc\"])\n",
    "plt.plot(history.history[\"val_acc\"])\n",
    "plt.title(\"model loss\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylim((0.2,0.4))\n",
    "plt.legend([\"train\", \"test\"], loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Overall, the performance of the raw multiclass classification problem is **bad**. It is an ambitious problem that require more time to solve. However, there are some encouraging signs. \n",
    "1. Tree-based models show that pos_score and neg_score are relevant features for the problem. But there are flaws on which we can work:\n",
    "    - easy: stemming as it is done makes it harder to match words of the tweet and the SentiWordNet\n",
    "    - hard: it is obvious that we would like to get more granular scores (not only posive and negative, but also hate, anger..). Could be interesting to spend time on building such lexicon.\n",
    "2. The model main difficulty is to detect relevant signs for rare classes. It is understandable and to fix that:\n",
    "    - ideally, gather more data corresponding to rare labels\n",
    "    - train model on a dataset that is constitued of evenly distributed labels\n",
    "3. The word2vec aggregating part is not optimal. It could be mixed with TF-IDF to give weights to each word when averaging\n",
    "    \n",
    "Also, the final business application may not require as much granularity in the labels. A positive/negative/objective classification could for example be sufficient. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
